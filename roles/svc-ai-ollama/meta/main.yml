---
galaxy_info:
  author: "Kevin Veen-Birkenbach"
  description: "Installs Ollama â€” a local model server for running open LLMs with a simple HTTP API."
  license: "Infinito.Nexus NonCommercial License"
  license_url: "https://s.infinito.nexus/license"
  company: | 
    Kevin Veen-Birkenbach
    Consulting & Coaching Solutions
    https://www.veen.world
  galaxy_tags:
    - ai
    - llm
    - inference
    - offline
    - privacy
    - self-hosted
    - ollama
  repository: "https://s.infinito.nexus/code"
  issue_tracker_url: "https://s.infinito.nexus/issues"
  documentation: "https://s.infinito.nexus/code/"
  logo:
    class: "fa-solid fa-microchip"
  run_after: [] 
dependencies: []
